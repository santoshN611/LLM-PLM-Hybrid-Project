# LLM-PLM-Hybrid-Project

A hybrid pipeline combining large language models (LLMs) and pretrained language models (PLMs) for protein existence classification and post-translational modification (PTM) site counting. This repository automates data collection, embedding generation, model training, retrieval indexing, and end-to-end evaluation.

This project was done for CSE 7850 at Georgia Institute of Technology in Spring 2025.

Authors:
* Santosh Nachimuthu
* Saiyash Vishnubhatt

## ğŸ“ Directory Structure

```bash
LLM-PLM-Hybrid-Project/
â”œâ”€â”€ Makefile                   # Orchestrates the full pipeline
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ tiny_heads/                # Pretrained tiny-head weights
â”‚   â”œâ”€â”€ pe.pt
â”‚   â””â”€â”€ ptm.pt
â””â”€â”€ llm_plm_hybrid/            # Main package
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ data/                  # Data ingestion & splitting
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ create_corpus.py   # Download & build raw UniProt corpus
    â”‚   â””â”€â”€ split_corpus.py    # Split into train/val/test
    â”œâ”€â”€ embeddings/            # Embedding generation & head training
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ generate_embeddings.py  # ESM-2 embedding pipeline
    â”‚   â”œâ”€â”€ train_heads.py          # Train tiny-head PE & PTM models
    â”‚   â””â”€â”€ tiny_heads.py           # Load trained tiny-head weights
    â”œâ”€â”€ retrieval/             # FAISS index and retrieval utilities
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ faiss_index.py     # Build FAISS index from embeddings
    â”‚   â”œâ”€â”€ retrieval.py       # (Optional) retrieval scripts
    â”‚   â””â”€â”€ retrieval_utils.py # Context-building & neighbor search
    â”œâ”€â”€ qa/                    # Retrieval-augmented generation (RAG)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ adapters.py        # BioBERT adapter modules
    â”‚   â””â”€â”€ rag_pipeline.py    # End-to-end RAG QA pipeline
    â”œâ”€â”€ evaluation/            # Evaluation scripts and tests
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ build_test_qa_corpus.py  # Build JSONL test QA set
    â”‚   â”œâ”€â”€ evaluate_pipeline.py    # Compute metrics + save results
    â”‚   â”œâ”€â”€ test_intent.py           # Unit test for intent parsing
    â”‚   â””â”€â”€ test_neighbors.py        # QA neighbor lookup examples
    â””â”€â”€ utils/                # Shared utilities
        â”œâ”€â”€ __init__.py
        â””â”€â”€ embedding_utils.py    # Helper functions for embeddings
```

## âš™ï¸ Installation

1. **Clone the repository**

   ```bash
   git clone <repo-url> LLM-PLM-Hybrid-Project
   cd LLM-PLM-Hybrid-Project
   ```

2. **Create a Python environment** (recommended):

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**:

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **System prerequisites**:

   - Python 3.8+
   - CUDA toolkit (if you plan to use GPU for ESM-2 and BioBERT)
   - FAISS (if not installed via pip, see [FAISS installation docs](https://github.com/facebookresearch/faiss))

## ğŸ¯ Pipeline Usage

The `Makefile` wraps all steps; to run end-to-end:

```bash
make all
```

Or execute each stage individually:

1. **Preprocess** (download & build raw corpus)
   ```bash
   make preprocess
   ```

2. **Split** (train/validation/test)
   ```bash
   make split
   ```

3. **Embed** (generate ESM-2 embeddings)
   ```bash
   make embed
   ```

4. **Train** (train tiny-head PE & PTM classifiers)
   ```bash
   make train
   ```

5. **Index** (build FAISS index on training embeddings)
   ```bash
   make index
   ```

6. **Build Test Corpus** (create QA JSONL)
   ```bash
   make build-test
   ```

7. **Evaluate** (run end-to-end QA & retrieval evaluation)
   ```bash
   make evaluate
   ```

## ğŸ“ Outputs

- **Data files** (`llm_plm_hybrid/data/`): `classification.csv`, `regression.csv`, splits (`_train`, `_val`, `_test`).
- **Embeddings** (`llm_plm_hybrid/embeddings/`): `.npz` files (`X`, `y`, `meta`), `.index` and `.meta.npy`.
- **Models** (`tiny_heads/`): `pe.pt` & `ptm.pt` PyTorch weights.
- **Test corpus** (`llm_plm_hybrid/evaluation/test_protein_qa.jsonl`): JSONL of QA pairs.
- **Evaluation results** (`eval_results.csv`): per-question metrics & retrieval ranks.

## ğŸ§° Tips & Troubleshooting

- Run commands from the project root (where the `Makefile` is located).
- If GPU OOM occurs during embedding, the script will automatically retry on CPU.
- To regenerate only the FAISS index after new embeddings:
  ```bash
  make index
  ```
- To manually inspect neighbor retrieval:
  ```bash
  python -m llm_plm_hybrid.evaluation.test_neighbors
  ```

---

